{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b62a2c5d",
      "metadata": {
        "id": "b62a2c5d"
      },
      "source": [
        "# **Tomato Disease Detection**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46257b70",
      "metadata": {
        "id": "46257b70"
      },
      "source": [
        "## **Introduction**:\n",
        "\n",
        "> #### *Problem Statement*:\n",
        "> > Few farmers are facing with issue with in the farm. There are lots of problems in the agricultural sector in the perspective of the farmer, but we can help them by integrating the AI Technology. Even after selecting and growing the crop in the field, few\n",
        "crop diseases are not identified by the farmer which results to decrease in the crop yield. This is the main problem in the field so we are going to solve this issue by developing a model which can recognize the disease that is caused by the input of an image of the diseased plant. By\n",
        "tackling this, we can increase the crop yield and maintain the crop production.\n",
        "\n",
        "> #### *Overview of the project*:\n",
        "> > This project involves building and loading the data, **Plant Village Dataset**, Exploratory Data Analysis, Model Building and Training.  \n",
        "> #### *Goal of this project*:\n",
        "> > The goal of this project is to build model for tomato crop and to observe the performance metrics of the model\n",
        "> #### *Result*:\n",
        "> > With this we can hence use the model for any web application for tomato crop managment systems or Tomato plant Disease detection system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6mC9IHY1B2GH",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6mC9IHY1B2GH",
        "outputId": "991dd4cc-be14-404c-c249-18d7a55cd2c7"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "#install kaggle\n",
        "pip install -q kaggle\n",
        "\n",
        "#create a Kaggle folder andcopy kaggle.json to copied folder\n",
        "echo '{\"username\":\"disha1503\",\"key\":\"3d1810121b6c88f023679868aa91845b\"}' > ~/.kaggle/kaggle.json\n",
        "\n",
        "#permission for json to act\n",
        "chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "#downloading the dataset\n",
        "kaggle datasets download -d shylesh101/tomato-leaf-disease\n",
        "\n",
        "# unziping the dataset\n",
        "unzip tomato-leaf-disease.zip\n",
        "\n",
        "# installing the tensorflow library\n",
        "pip install tensorflow\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c752237a",
      "metadata": {
        "id": "c752237a"
      },
      "source": [
        "### Importing all the required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ca753a9",
      "metadata": {
        "id": "4ca753a9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import seaborn as sns\n",
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()\n",
        "import os\n",
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "import math\n",
        "from tensorflow import keras\n",
        "# import tensorflow_addons as tfa\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from PIL import Image, ImageEnhance\n",
        "import random\n",
        "import cv2\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from tqdm import tqdm\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "import tensorflow_hub as hub\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.models import load_model\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bae61e2c",
      "metadata": {
        "id": "bae61e2c"
      },
      "source": [
        "## 1. Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "740c0d28",
      "metadata": {
        "id": "740c0d28"
      },
      "source": [
        "### Defining a function to get the path for folder paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Jl_2J-GCCUCo",
      "metadata": {
        "id": "Jl_2J-GCCUCo"
      },
      "outputs": [],
      "source": [
        "train_data_dir = '/content/tomato_dataset/train'\n",
        "test_data_dir = '/content/tomato_dataset/test'\n",
        "val_data_dir = '/content/tomato_dataset/valid'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70639311",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70639311",
        "outputId": "fbc0db11-9bb7-498c-be30-e74abdf64efa"
      },
      "outputs": [],
      "source": [
        "def get_path(plant_dir:str, dir_test:str):\n",
        "    if dir_test == 'Test':\n",
        "        return test_data_dir\n",
        "    elif dir_test == 'Train':\n",
        "        return train_data_dir\n",
        "    elif dir_test == 'Valid':\n",
        "        return val_data_dir\n",
        "plant_path = '/content/tomato_dataset'\n",
        "plant_dirs = os.listdir(\"/content/tomato_dataset\")\n",
        "plant_dirs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5df254e1",
      "metadata": {
        "id": "5df254e1"
      },
      "source": [
        "### Printing the information about the Training set, the directories and the images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "115ff1e0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "115ff1e0",
        "outputId": "fdf0fecb-e1d9-4bc0-8abf-3cbcd5f29f30"
      },
      "outputs": [],
      "source": [
        "img_dim = (256,256)\n",
        "batch_size = 32\n",
        "num_channels = 3\n",
        "input_size = (batch_size, img_dim[0], img_dim[1], num_channels)\n",
        "train_dataset = {}\n",
        "\n",
        "print(\"-_-_-_-_-_-_-_-_-_-_Images & Classes for Training-_-_-_-_-_-_-_-_-_-_\")\n",
        "for plant in plant_dirs:\n",
        "    print(f'>>> No of Images & Classes in \"{plant}\" directory')\n",
        "    train_dataset[plant] = image_dataset_from_directory(get_path(plant, \"Train\"),\n",
        "                                                        shuffle=True,\n",
        "                                                        labels = 'inferred',\n",
        "                                                        label_mode = 'int',\n",
        "                                                        image_size = img_dim,\n",
        "                                                        batch_size = batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee0b90a1",
      "metadata": {
        "id": "ee0b90a1"
      },
      "source": [
        "### Printing the disease names of each plant"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87074bf8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87074bf8",
        "outputId": "fd438631-a9fa-4b6a-af57-287083f2820f"
      },
      "outputs": [],
      "source": [
        "classes  ={}\n",
        "for plant in plant_dirs:\n",
        "    print(f'>>> Classes in \"{plant}\" dataset :-')\n",
        "    classes[plant] = []\n",
        "    for num, cat in enumerate(train_dataset[plant].class_names, start=1):\n",
        "        classes[plant].append(cat)\n",
        "        print(num, cat)\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a352dd0d",
      "metadata": {
        "id": "a352dd0d"
      },
      "source": [
        "### Plotting few random samples from each plant directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a30913d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1a30913d",
        "outputId": "5d0f012a-69ce-4180-e3e5-46b07d9a7217"
      },
      "outputs": [],
      "source": [
        "for plant in plant_dirs:\n",
        "    print(f'>>>> Sample Images of \"{plant}\" dataset')\n",
        "    plt.figure(figsize=(14,5))\n",
        "    for image_batch, image_label in train_dataset[plant].take(1):\n",
        "        for i in range(10):\n",
        "            plt.subplot(2,5,i+1)\n",
        "            plt.imshow(image_batch[i].numpy().astype('uint8'))\n",
        "            plt.title(classes[plant][image_label[i]])\n",
        "            plt.axis('off')\n",
        "        plt.show()\n",
        "    print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ob5sT4lgeIQC",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ob5sT4lgeIQC",
        "outputId": "b6a2057b-7e3f-4490-b281-cba8bec402d7"
      },
      "outputs": [],
      "source": [
        "# getting values of training dataset\n",
        "train_dataset.values()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "564f3a67",
      "metadata": {
        "id": "564f3a67"
      },
      "source": [
        "### Plotting the standardized images for random plant leaf images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ff04f0c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3ff04f0c",
        "outputId": "e5065cde-1591-407b-dee6-d91ab2434710"
      },
      "outputs": [],
      "source": [
        "# Creating a function for standardizing images\n",
        "def std_img(img):\n",
        "    img_flat = img.reshape(-1,3)\n",
        "    scaler = StandardScaler()\n",
        "    img_std = scaler.fit_transform(img_flat)\n",
        "    img_std = img_std.reshape(256,256,3)\n",
        "    return img_std\n",
        "\n",
        "# getting the standardized images with labels\n",
        "tomato_img = []\n",
        "tomato_label = []\n",
        "for img,label in train_dataset[plant].take(1):\n",
        "    for i in range(5):\n",
        "        tomato_img.append(img[i])\n",
        "        tomato_label.append(classes[\"test\"][label[i]])\n",
        "\n",
        "for i in range(5):\n",
        "    # typcasting\n",
        "    nik = np.array(tomato_img[i]).astype('uint8')\n",
        "    img_std = std_img(nik)\n",
        "\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(nik)\n",
        "    plt.title(\"Tomato \"+tomato_label[i])\n",
        "    plt.axis('off')\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(img_std)\n",
        "    plt.title('Standardized Image')\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d31b82d",
      "metadata": {
        "id": "0d31b82d"
      },
      "source": [
        "### Plotting the 32X32 patch format of a image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22e6c236",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "id": "22e6c236",
        "outputId": "d9a5449f-7b98-46ab-b630-665f7fb34636"
      },
      "outputs": [],
      "source": [
        "image_size = 224\n",
        "img_height, img_width = 512, 512\n",
        "patch_size = 32\n",
        "num_patches = (image_size // patch_size) ** 2\n",
        "class Patches(layers.Layer):\n",
        "\n",
        "    def __init__(self, patch_size):\n",
        "        super(Patches, self).__init__()\n",
        "        super(Patches, self).__init__()\n",
        "        self.patch_size = patch_size\n",
        "    def call(self, images):\n",
        "        batch_size = tf.shape(images)[0]\n",
        "        patches = tf.image.extract_patches(\n",
        "            images=images,\n",
        "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
        "            strides=[1, self.patch_size, self.patch_size, 1],\n",
        "            rates=[1, 1, 1, 1],\n",
        "            padding=\"VALID\",\n",
        "        )\n",
        "        patch_dims = patches.shape[-1]\n",
        "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
        "        return patches\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "plt.figure(figsize=(4, 4))\n",
        "\n",
        "target = \"/content/tomato_dataset/train/Tomato___Bacterial_spot\"\n",
        "random_num = random.choice(os.listdir(target))\n",
        "image = mpimg.imread(\"/content/tomato_dataset/train/Tomato___Bacterial_spot/\" + random_num)\n",
        "plt.imshow(image.astype(\"uint8\"))\n",
        "plt.axis(\"off\")\n",
        "resized_image = tf.image.resize(\n",
        "    tf.convert_to_tensor([image]), size=(image_size, image_size)\n",
        ")\n",
        "patches = Patches(patch_size)(resized_image)\n",
        "print(f\"Image size: {image_size} X {image_size}\")\n",
        "print(f\"Patch size: {patch_size} X {patch_size}\")\n",
        "print(f\"Patches per image: {patches.shape[1]}\")\n",
        "print(f\"Elements per patch: {patches.shape[-1]}\")\n",
        "n = int(np.sqrt(patches.shape[1]))\n",
        "plt.figure(figsize=(4, 4))\n",
        "for i, patch in enumerate(patches[0]):\n",
        "    ax = plt.subplot(n, n, i + 1)\n",
        "    patch_img = tf.reshape(patch, (patch_size, patch_size, 3))\n",
        "    plt.imshow(patch_img.numpy().astype(\"uint8\"))\n",
        "    plt.axis(\"off\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a201c306",
      "metadata": {
        "id": "a201c306"
      },
      "source": [
        "# **Model Development**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5639944e",
      "metadata": {
        "id": "5639944e"
      },
      "source": [
        "### Declaring the paths for the training, testing, validation path, labels for the given plant diseases and the output length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4b5b5b6",
      "metadata": {
        "id": "c4b5b5b6"
      },
      "outputs": [],
      "source": [
        "train_path = f\"{plant_path}/train\"\n",
        "val_path = f\"{plant_path}/valid\"\n",
        "test_path = f\"{plant_path}/test\"\n",
        "out_labels = os.listdir(f\"{plant_path}/train/\")\n",
        "out_len = len(out_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mwck_qKbYVRp",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwck_qKbYVRp",
        "outputId": "17c3bc7c-40ce-45ae-b645-e778c4b18062"
      },
      "outputs": [],
      "source": [
        "out_len"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae00876b",
      "metadata": {
        "id": "ae00876b"
      },
      "source": [
        "### Declaring the batch size of 64 and the image size of 224X224 pixels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86638231",
      "metadata": {
        "id": "86638231"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "img_height = 224"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30a6f5b0",
      "metadata": {
        "id": "30a6f5b0"
      },
      "source": [
        "### Declare the ImageDataGenerator for the train_datagen and test_datagen, val_datagen. For train_datagen the images are augumented and for all the three datagenerators the pixels are scaled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19f4ac01",
      "metadata": {
        "id": "19f4ac01"
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255.,rotation_range=20,shear_range=0.15,horizontal_flip=True,)\n",
        "val_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0455c6a",
      "metadata": {
        "id": "f0455c6a"
      },
      "source": [
        "### Declaring the train, test and valid sets for the input to the model, making every image to be of the size 224X224 pixels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0ec5a5b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0ec5a5b",
        "outputId": "4a708b18-b85a-4b62-89be-e87f4382977b"
      },
      "outputs": [],
      "source": [
        "train_set = train_datagen.flow_from_directory(train_path,target_size = (224,224),batch_size = 64,shuffle = True,class_mode = 'categorical')\n",
        "val_set = val_datagen.flow_from_directory(val_path,target_size = (224, 224),batch_size = 64,shuffle = False,class_mode = 'categorical')\n",
        "test_set = val_datagen.flow_from_directory(test_path,target_size = (224, 224),batch_size = 64,shuffle = False,class_mode = 'categorical')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66d7914e",
      "metadata": {
        "id": "66d7914e"
      },
      "source": [
        "### Loading the pretrained VIT model with RESNET50 as backbone with 32 patch size and pretrained on ImageNet-21k dataset. Building a classifier head over the pretrained VIT Model with out_len as the output shape which is equal to the number of disease of plant"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99697e44",
      "metadata": {
        "id": "99697e44"
      },
      "outputs": [],
      "source": [
        "fe_L2 = hub.KerasLayer(\"https://tfhub.dev/sayakpaul/vit_r50_l32_fe/1\",input_shape = (224,224,3),trainable = False,name = \"Pre_Trained_\")\n",
        "VIT = tf.keras.Sequential([\n",
        "    fe_L2,\n",
        "    layers.Dense(128,activation = \"relu\"),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(out_len, activation = \"softmax\", name = \"output_layer\")\n",
        "])\n",
        "\n",
        "VIT.compile(loss = \"categorical_crossentropy\",optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0001),metrics = [\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62eda973",
      "metadata": {
        "id": "62eda973"
      },
      "source": [
        "### Trianing the model for 10 epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3471a8f0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3471a8f0",
        "outputId": "93f54dfe-0632-4947-fc41-504317eb966e"
      },
      "outputs": [],
      "source": [
        "epochs = 10\n",
        "r=VIT.fit(train_set,epochs = epochs,validation_data = val_set,steps_per_epoch=len(train_set),validation_steps = len(val_set))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50400b61",
      "metadata": {
        "id": "50400b61"
      },
      "source": [
        "### Saving the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b03fcbc3",
      "metadata": {
        "id": "b03fcbc3"
      },
      "outputs": [],
      "source": [
        "# models_name = \"plant_disease_detection\"+\"_model_keras.keras\"\n",
        "VIT.save(plant_disease_model.h5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DrT52M8hDqYB",
      "metadata": {
        "id": "DrT52M8hDqYB"
      },
      "outputs": [],
      "source": [
        "loaded_model = tf.keras.models.load_model(plant_disease_model.h5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76f66afd",
      "metadata": {
        "id": "76f66afd"
      },
      "source": [
        "### To make the model file to be availabel for download, run the following code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7M65axyGpxTa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "7M65axyGpxTa",
        "outputId": "4de1f636-6c59-4e09-b259-d2a8fb0154f1"
      },
      "outputs": [],
      "source": [
        "!zip -r model.zip /content/plant_disease_detection_model2.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "W7ZpIs8rSQSb",
      "metadata": {
        "id": "W7ZpIs8rSQSb"
      },
      "outputs": [],
      "source": [
        "!cp /content/plant_disease_detection_model_keras.keras /content/drive/MyDrive/cnnModel/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "w6rDDVLiWtUR",
      "metadata": {
        "id": "w6rDDVLiWtUR"
      },
      "outputs": [],
      "source": [
        "!cp /content/model.zip /content/model1.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "p2k8W3_DW3yE",
      "metadata": {
        "id": "p2k8W3_DW3yE"
      },
      "outputs": [],
      "source": [
        "!mv /content/model1.zip /content/model_h5.h5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "6a2add00",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hello\n"
          ]
        }
      ],
      "source": [
        "# %%shell\n",
        "# print('hello')\n",
        "# pip install  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "8LWF8NpwZSIv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "8LWF8NpwZSIv",
        "outputId": "75927a1d-097e-4639-aafe-10fa2cf302f2"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "<class 'keras.src.models.sequential.Sequential'> could not be deserialized properly. Please ensure that components that are Python object instances (layers, models, etc.) returned by `get_config()` are explicitly deserialized in the model's `from_config()` method.\n\nconfig={'module': 'keras', 'class_name': 'Sequential', 'config': {'name': 'sequential', 'layers': [{'module': 'keras.layers', 'class_name': 'InputLayer', 'config': {'batch_input_shape': [None, 224, 224, 3], 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'Pre_Trained__input'}, 'registered_name': None}, {'module': 'tensorflow_hub.keras_layer', 'class_name': 'KerasLayer', 'config': {'name': 'Pre_Trained_', 'trainable': False, 'dtype': 'float32', 'batch_input_shape': [None, 224, 224, 3], 'handle': 'https://tfhub.dev/sayakpaul/vit_r50_l32_fe/1'}, 'registered_name': 'KerasLayer', 'build_config': {'input_shape': [None, 224, 224, 3]}}, {'module': 'keras.layers', 'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 128, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 1024]}}, {'module': 'keras.layers', 'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 128]}}, {'module': 'keras.layers', 'class_name': 'Dense', 'config': {'name': 'output_layer', 'trainable': True, 'dtype': 'float32', 'units': 10, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 128]}}]}, 'registered_name': None, 'build_config': {'input_shape': [None, 224, 224, 3]}, 'compile_config': {'optimizer': {'module': 'keras.optimizers', 'class_name': 'Adam', 'config': {'name': 'Adam', 'weight_decay': None, 'clipnorm': None, 'global_clipnorm': None, 'clipvalue': None, 'use_ema': False, 'ema_momentum': 0.99, 'ema_overwrite_frequency': None, 'jit_compile': True, 'is_legacy_optimizer': False, 'learning_rate': 9.999999747378752e-05, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}, 'registered_name': None}, 'loss': 'categorical_crossentropy', 'metrics': ['accuracy'], 'loss_weights': None, 'weighted_metrics': None, 'run_eagerly': None, 'steps_per_execution': None, 'jit_compile': None}}.\n\nException encountered: <class 'tensorflow_hub.keras_layer.KerasLayer'> could not be deserialized properly. Please ensure that components that are Python object instances (layers, models, etc.) returned by `get_config()` are explicitly deserialized in the model's `from_config()` method.\n\nconfig={'module': 'tensorflow_hub.keras_layer', 'class_name': 'KerasLayer', 'config': {'name': 'Pre_Trained_', 'trainable': False, 'dtype': 'float32', 'batch_input_shape': [None, 224, 224, 3], 'handle': 'https://tfhub.dev/sayakpaul/vit_r50_l32_fe/1'}, 'registered_name': 'KerasLayer', 'build_config': {'input_shape': [None, 224, 224, 3]}}.\n\nException encountered: Error when deserializing class 'KerasLayer' using config={'name': 'Pre_Trained_', 'trainable': False, 'dtype': 'float32', 'batch_input_shape': [None, 224, 224, 3], 'handle': 'https://tfhub.dev/sayakpaul/vit_r50_l32_fe/1'}.\n\nException encountered: <urlopen error [Errno -2] Name or service not known>",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1347\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m                 h.request(req.get_method(), req.selector, req.data, headers,\n\u001b[0m\u001b[1;32m   1349\u001b[0m                           encode_chunked=req.has_header('Transfer-encoding'))\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1282\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1283\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1328\u001b[0m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1277\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1037\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1038\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1039\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    975\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 976\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    977\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1448\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    941\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"http.client.connect\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m         self.sock = self._create_connection(\n\u001b[0m\u001b[1;32m    943\u001b[0m             (self.host,self.port), self.timeout, self.source_address)\n",
            "\u001b[0;32m/usr/lib/python3.10/socket.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address)\u001b[0m\n\u001b[1;32m    823\u001b[0m     \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgetaddrinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSOCK_STREAM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m         \u001b[0maf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/socket.py\u001b[0m in \u001b[0;36mgetaddrinfo\u001b[0;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0maddrlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 955\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_socket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    956\u001b[0m         \u001b[0maf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mgaierror\u001b[0m: [Errno -2] Name or service not known",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mURLError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/base_layer.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_hub/keras_layer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, handle, trainable, arguments, _sentinel, tags, signature, signature_outputs_as_dict, output_key, output_shape, load_options, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_hub_module_v1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_is_hub_module_v1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_hub/keras_layer.py\u001b[0m in \u001b[0;36mload_module\u001b[0;34m(handle, tags, load_options)\u001b[0m\n\u001b[1;32m    466\u001b[0m           \u001b[0mset_load_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodule_v2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mset_load_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_hub/module_v2.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(handle, tags, options)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expected a string, got %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   \u001b[0mmodule_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m   \u001b[0mis_hub_module_v1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_module_proto_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_hub/module_v2.py\u001b[0m in \u001b[0;36mresolve\u001b[0;34m(handle)\u001b[0m\n\u001b[1;32m     54\u001b[0m   \"\"\"\n\u001b[0;32m---> 55\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_hub/registry.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     48\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mimpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_supported\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_hub/compressed_module_resolver.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, handle)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     return resolver.atomic_download(handle, download, module_dir,\n\u001b[0m\u001b[1;32m     82\u001b[0m                                     self._lock_file_timeout_sec())\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_hub/resolver.py\u001b[0m in \u001b[0;36matomic_download\u001b[0;34m(handle, download_fn, module_dir, lock_file_timeout_sec)\u001b[0m\n\u001b[1;32m    420\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMakeDirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m     \u001b[0mdownload_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmp_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m     \u001b[0;31m# Write module descriptor to capture information about which module was\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_hub/compressed_module_resolver.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(handle, tmp_dir)\u001b[0m\n\u001b[1;32m     76\u001b[0m           self._append_compressed_format_query(handle))\n\u001b[0;32m---> 77\u001b[0;31m       \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_urlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m       return resolver.DownloadManager(handle).download_and_uncompress(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_hub/resolver.py\u001b[0m in \u001b[0;36m_call_urlopen\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    527\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'urllib.Request'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 536\u001b[0;31m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0m\u001b[1;32m    537\u001b[0m                                   '_open', req)\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36mhttps_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1390\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mhttps_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1391\u001b[0;31m             return self.do_open(http.client.HTTPSConnection, req,\n\u001b[0m\u001b[1;32m   1392\u001b[0m                 context=self._context, check_hostname=self._check_hostname)\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1350\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# timeout error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1351\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1352\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mURLError\u001b[0m: <urlopen error [Errno -2] Name or service not known>",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/saving/serialization_lib.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    717\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m             \u001b[0minstance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minner_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    719\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/base_layer.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config)\u001b[0m\n\u001b[1;32m    856\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m             raise TypeError(\n\u001b[0m\u001b[1;32m    858\u001b[0m                 \u001b[0;34mf\"Error when deserializing class '{cls.__name__}' using \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Error when deserializing class 'KerasLayer' using config={'name': 'Pre_Trained_', 'trainable': False, 'dtype': 'float32', 'batch_input_shape': [None, 224, 224, 3], 'handle': 'https://tfhub.dev/sayakpaul/vit_r50_l32_fe/1'}.\n\nException encountered: <urlopen error [Errno -2] Name or service not known>",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/saving/serialization_lib.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    717\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m             \u001b[0minstance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minner_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    719\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/models/sequential.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m                 layer = serialization_lib.deserialize_keras_object(\n\u001b[0m\u001b[1;32m    339\u001b[0m                     \u001b[0mlayer_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/saving/serialization_lib.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m             raise TypeError(\n\u001b[0m\u001b[1;32m    721\u001b[0m                 \u001b[0;34mf\"{cls} could not be deserialized properly. Please\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: <class 'tensorflow_hub.keras_layer.KerasLayer'> could not be deserialized properly. Please ensure that components that are Python object instances (layers, models, etc.) returned by `get_config()` are explicitly deserialized in the model's `from_config()` method.\n\nconfig={'module': 'tensorflow_hub.keras_layer', 'class_name': 'KerasLayer', 'config': {'name': 'Pre_Trained_', 'trainable': False, 'dtype': 'float32', 'batch_input_shape': [None, 224, 224, 3], 'handle': 'https://tfhub.dev/sayakpaul/vit_r50_l32_fe/1'}, 'registered_name': 'KerasLayer', 'build_config': {'input_shape': [None, 224, 224, 3]}}.\n\nException encountered: Error when deserializing class 'KerasLayer' using config={'name': 'Pre_Trained_', 'trainable': False, 'dtype': 'float32', 'batch_input_shape': [None, 224, 224, 3], 'handle': 'https://tfhub.dev/sayakpaul/vit_r50_l32_fe/1'}.\n\nException encountered: <urlopen error [Errno -2] Name or service not known>",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_53558/1704873425.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./plant_disease_detection_model_keras.keras'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m model= tf.keras.models.load_model(\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m \u001b[0;34m'KerasLayer'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasLayer\u001b[0m \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_keras_zip\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         return saving_lib.load_model(\n\u001b[0m\u001b[1;32m    177\u001b[0m             \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/saving/saving_lib.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    150\u001b[0m             )\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             return _load_model_from_fileobj(\n\u001b[0m\u001b[1;32m    153\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m             )\n",
            "\u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/saving/saving_lib.py\u001b[0m in \u001b[0;36m_load_model_from_fileobj\u001b[0;34m(fileobj, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;31m# Construct the model from the configuration file in the archive.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mObjectSharingScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m             model = deserialize_keras_object(\n\u001b[0m\u001b[1;32m    171\u001b[0m                 \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msafe_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             )\n",
            "\u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/saving/serialization_lib.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0minstance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minner_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m             raise TypeError(\n\u001b[0m\u001b[1;32m    721\u001b[0m                 \u001b[0;34mf\"{cls} could not be deserialized properly. Please\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m                 \u001b[0;34m\" ensure that components that are Python object\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: <class 'keras.src.models.sequential.Sequential'> could not be deserialized properly. Please ensure that components that are Python object instances (layers, models, etc.) returned by `get_config()` are explicitly deserialized in the model's `from_config()` method.\n\nconfig={'module': 'keras', 'class_name': 'Sequential', 'config': {'name': 'sequential', 'layers': [{'module': 'keras.layers', 'class_name': 'InputLayer', 'config': {'batch_input_shape': [None, 224, 224, 3], 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'Pre_Trained__input'}, 'registered_name': None}, {'module': 'tensorflow_hub.keras_layer', 'class_name': 'KerasLayer', 'config': {'name': 'Pre_Trained_', 'trainable': False, 'dtype': 'float32', 'batch_input_shape': [None, 224, 224, 3], 'handle': 'https://tfhub.dev/sayakpaul/vit_r50_l32_fe/1'}, 'registered_name': 'KerasLayer', 'build_config': {'input_shape': [None, 224, 224, 3]}}, {'module': 'keras.layers', 'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 128, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 1024]}}, {'module': 'keras.layers', 'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 128]}}, {'module': 'keras.layers', 'class_name': 'Dense', 'config': {'name': 'output_layer', 'trainable': True, 'dtype': 'float32', 'units': 10, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 128]}}]}, 'registered_name': None, 'build_config': {'input_shape': [None, 224, 224, 3]}, 'compile_config': {'optimizer': {'module': 'keras.optimizers', 'class_name': 'Adam', 'config': {'name': 'Adam', 'weight_decay': None, 'clipnorm': None, 'global_clipnorm': None, 'clipvalue': None, 'use_ema': False, 'ema_momentum': 0.99, 'ema_overwrite_frequency': None, 'jit_compile': True, 'is_legacy_optimizer': False, 'learning_rate': 9.999999747378752e-05, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}, 'registered_name': None}, 'loss': 'categorical_crossentropy', 'metrics': ['accuracy'], 'loss_weights': None, 'weighted_metrics': None, 'run_eagerly': None, 'steps_per_execution': None, 'jit_compile': None}}.\n\nException encountered: <class 'tensorflow_hub.keras_layer.KerasLayer'> could not be deserialized properly. Please ensure that components that are Python object instances (layers, models, etc.) returned by `get_config()` are explicitly deserialized in the model's `from_config()` method.\n\nconfig={'module': 'tensorflow_hub.keras_layer', 'class_name': 'KerasLayer', 'config': {'name': 'Pre_Trained_', 'trainable': False, 'dtype': 'float32', 'batch_input_shape': [None, 224, 224, 3], 'handle': 'https://tfhub.dev/sayakpaul/vit_r50_l32_fe/1'}, 'registered_name': 'KerasLayer', 'build_config': {'input_shape': [None, 224, 224, 3]}}.\n\nException encountered: Error when deserializing class 'KerasLayer' using config={'name': 'Pre_Trained_', 'trainable': False, 'dtype': 'float32', 'batch_input_shape': [None, 224, 224, 3], 'handle': 'https://tfhub.dev/sayakpaul/vit_r50_l32_fe/1'}.\n\nException encountered: <urlopen error [Errno -2] Name or service not known>"
          ]
        }
      ],
      "source": [
        "# import tensorflow as tf\n",
        "\n",
        "# # Load the model using custom_objects\n",
        "# model_path = 'C:\\pythonProject1\\plant_disease_detection_model_keras.keras'\n",
        "# model_with_dropout = tf.keras.models.load_model(model_path)\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "# Path to the model file\n",
        "model_path = './plant_disease_detection_model_keras.keras'\n",
        "\n",
        "model= tf.keras.models.load_model(\n",
        "    model_path,\n",
        "    custom_objects= { 'KerasLayer' : hub.KerasLayer }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-ZdzuM_Kqegu",
      "metadata": {
        "id": "-ZdzuM_Kqegu"
      },
      "outputs": [],
      "source": [
        "r.history.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e30b137",
      "metadata": {
        "id": "2e30b137"
      },
      "source": [
        "### Predicting the test_set for the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27de924f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27de924f",
        "outputId": "dc805f67-394c-4f9c-c30c-5a238fbd78a8"
      },
      "outputs": [],
      "source": [
        "Y_pred = VIT.predict(test_set, steps = len(test_set) )\n",
        "y_pred = np.argmax(Y_pred, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hoGApfPmrMtC",
      "metadata": {
        "id": "hoGApfPmrMtC"
      },
      "outputs": [],
      "source": [
        "y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ced30193",
      "metadata": {
        "id": "ced30193"
      },
      "source": [
        "### Plotting the confusion matrix for given y_pred and y_true"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "011e28f0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 889
        },
        "id": "011e28f0",
        "outputId": "37a91d14-f585-456c-b2b5-58cea35fa2a0"
      },
      "outputs": [],
      "source": [
        "cf = confusion_matrix(test_set.classes, y_pred)\n",
        "list = os.listdir(f\"{plant_path}/train\")\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cf, annot=True, fmt='d', cmap='Blues',xticklabels=out_labels,yticklabels=out_labels)\n",
        "plt.title(f'Confusion Matrix of {plant} with Accuracy : {accuracy_score(test_set.classes, y_pred) * 100:.2f}%')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt_name = plant+\"_CF.png\"\n",
        "plt.savefig(plt_name)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb230c87",
      "metadata": {
        "id": "bb230c87"
      },
      "source": [
        "### Printing the classification report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f846ba91",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f846ba91",
        "outputId": "bf3d27d7-78df-415b-a438-d56b1f6ee65c"
      },
      "outputs": [],
      "source": [
        "print('-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_>>>>Classification Report<<<<-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_')\n",
        "print(classification_report(test_set.classes, y_pred, target_names=out_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "deed1aef",
      "metadata": {
        "id": "deed1aef"
      },
      "source": [
        "### Plotting the model Accuracy and Loss Graphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6bcd8d58",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "id": "6bcd8d58",
        "outputId": "96bce321-9373-4abd-828e-1182ee2a6cdb"
      },
      "outputs": [],
      "source": [
        "epochs = [i for i in range(10)]\n",
        "fig , ax = plt.subplots(1,2)\n",
        "train_acc = r.history['accuracy']\n",
        "train_loss = r.history['loss']\n",
        "val_acc = r.history['val_accuracy']\n",
        "val_loss = r.history['val_loss']\n",
        "fig.set_size_inches(16,9)\n",
        "\n",
        "ax[0].plot(epochs , train_acc , 'go-' , label = 'Training Accuracy')\n",
        "ax[0].plot(epochs , val_acc , 'ro-' , label = 'Validation Accuracy')\n",
        "ax[0].set_title('Training & Validation Accuracy')\n",
        "ax[0].legend()\n",
        "ax[0].set_xlabel(\"Epochs\")\n",
        "ax[0].set_ylabel(\"Accuracy\")\n",
        "\n",
        "ax[1].plot(epochs , train_loss , 'g-o' , label = 'Training Loss')\n",
        "ax[1].plot(epochs , val_loss , 'r-o' , label = 'Validation Loss')\n",
        "ax[1].set_title('Training & Validation Loss')\n",
        "ax[1].legend()\n",
        "ax[1].set_xlabel(\"Epochs\")\n",
        "ax[1].set_ylabel(\"Loss\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QjeKOnwUHDnj",
      "metadata": {
        "id": "QjeKOnwUHDnj"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = VIT.evaluate(test_set)\n",
        "print(f'Test Loss: {test_loss}, Test Accuracy: {test_accuracy}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8hAqUh7usdpo",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "collapsed": true,
        "id": "8hAqUh7usdpo",
        "outputId": "f479dcb0-ff93-4dc1-c1be-360e57d8a42b"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20,20))\n",
        "for image_batch , image_label in test_set.take(1):\n",
        "    for i in range(20):\n",
        "        plt.subplot(5,4,i+1)\n",
        "        plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n",
        "        plt.title(class_label[image_label[i].numpy()])\n",
        "        plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jwGnt0b8uObp",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jwGnt0b8uObp",
        "outputId": "b93202df-a402-4f10-f613-47f8ccfe0a0e"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "val_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.resnet.preprocess_input)\n",
        "\n",
        "# Flow training and validation data in batches using generators\n",
        "train_gen = val_datagen.flow_from_directory(test_data_dir, target_size=(224, 224), batch_size=32, class_mode='categorical')\n",
        "# Define the class names\n",
        "class_names = train_dataset['train'].class_names\n",
        "# model_with_dropout = loaded_model\n",
        "# Function to preprocess a single image\n",
        "def preprocess_image(img):\n",
        "    img = tf.image.resize(img, (224, 224))  # Resize to the input shape required by the model\n",
        "    img = preprocess_input(img)  # Preprocess the image\n",
        "    img = tf.expand_dims(img, 0)  # Add batch dimension\n",
        "    return img\n",
        "\n",
        "# Function to predict the class and confidence\n",
        "def predict(img):\n",
        "    img_array = preprocess_image(img)  # Preprocess the image\n",
        "    predictions = model_with_dropout.predict(img_array)\n",
        "    predicted_class = class_names[np.argmax(predictions[0])]\n",
        "    confidence = round(100 * (np.max(predictions[0])), 2)\n",
        "    return predicted_class, confidence\n",
        "\n",
        "# Load the model\n",
        "# model_path = '/content/cnnResnet50Model.h5'\n",
        "# model_with_dropout = tf.keras.models.load_model(model_path)\n",
        "\n",
        "# Plotting the images with predictions\n",
        "plt.figure(figsize=(15, 15))\n",
        "\n",
        "for images, labels in train_gen:\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        image = images[i]\n",
        "        plt.imshow(image.astype(\"uint16\"))\n",
        "\n",
        "        predicted_class, confidence = predict(image)\n",
        "        index = labels[i].argmax(axis=0)\n",
        "        actual_class = class_names[index]\n",
        "\n",
        "        plt.title(f\"Actual: {actual_class}\\nPredicted: {predicted_class}\\nConfidence: {confidence}%\")\n",
        "        plt.axis(\"off\")\n",
        "    break  # Break after the first batch\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8IZO7Mgu9ri",
      "metadata": {
        "id": "c8IZO7Mgu9ri"
      },
      "outputs": [],
      "source": [
        "classes.get('train')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "datasetId": 3146821,
          "sourceId": 5441978,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30635,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 950.858914,
      "end_time": "2024-01-17T07:17:40.724413",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2024-01-17T07:01:49.865499",
      "version": "2.4.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
