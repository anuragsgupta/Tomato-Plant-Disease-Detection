{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anuragsgupta/Tomato-Plant-Disease-Detection/blob/main/PlantDisease.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UP2HMwL-mv__"
      },
      "source": [
        "## Importing Dataset from Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "EzS_lyksMCBM"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "#install kaggle\n",
        "pip install -q kaggle\n",
        "\n",
        "#create a Kaggle folder #copy kaggle.json to copied folder\n",
        "echo '{\"username\":\"disha1503\",\"key\":\"3d1810121b6c88f023679868aa91845b\"}' > ~/.kaggle/kaggle.json\n",
        "\n",
        "#permission for json to act\n",
        "chmod 600 ~/.kaggle/kaggle.json\n",
        "kaggle datasets download -d shylesh101/tomato-leaf-disease\n",
        "unzip tomato-leaf-disease.zip\n",
        "pip install tensorflow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J6v5xR3tMvHL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1da16ae8-12ec-4664-90b8-12a182bf31f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/shylesh101/tomato-leaf-disease\n",
            "License(s): unknown\n",
            "tomato-leaf-disease.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Archive:  tomato-leaf-disease.zip\n",
            "replace tomato_dataset/test/Tomato___Bacterial_spot/0c32d6d5-bf5b-4904-8108-d7a901f2cb6b___UF.GRC_BS_Lab Leaf 8662.JPG? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "# from IPython.display import clear_output\n",
        "# !kaggle datasets download -d shylesh101/tomato-leaf-disease\n",
        "# !unzip tomato-leaf-disease.zip\n",
        "# !pip install tensorflow\n",
        "# clear_output()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7lg1ag9m7UA"
      },
      "source": [
        "## Importing essential Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "-jVDyMs03ncZ"
      },
      "outputs": [],
      "source": [
        "# Importing all the libraries needed\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import os, requests, cv2, random\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, GlobalAveragePooling2D,BatchNormalization , Add, Input, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping,ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import Sequential, layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow import keras\n",
        "from sklearn.metrics import confusion_matrix,classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OzZyHaRN4h7j"
      },
      "outputs": [],
      "source": [
        "train_data_dir = '/content/tomato_dataset/train'\n",
        "test_data_dir = '/content/tomato_dataset/test'\n",
        "val_data_dir = '/content/tomato_dataset/valid'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPdqDOV0mjMw"
      },
      "source": [
        "## Image Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dN6DlzRH5tUF"
      },
      "outputs": [],
      "source": [
        "# ImageDataGenerator\n",
        "# train_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.resnet.preprocess_input)\n",
        "# val_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.resnet.preprocess_input)\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1/255.0,# Normalizing images\n",
        "                                  shear_range=0.2,\n",
        "                                  rotation_range=10,\n",
        "                                  zoom_range=0.2,\n",
        "                                  horizontal_flip=True,\n",
        "                                  validation_split=0.2)# specifying the validation split inside the function\n",
        "\n",
        "# ImageDataGenerator(\n",
        "#         rotation_range=10, # rotation\n",
        "#         width_shift_range=0.2, # horizontal shift\n",
        "#         height_shift_range=0.2, # vertical shift\n",
        "#         zoom_range=0.2, # zoom\n",
        "#         horizontal_flip=True, # horizontal flip\n",
        "#         brightness_range=[0.2,1.2]) # brightnessLearning Rate\t.001\n",
        "# Drop out\t0.01\n",
        "# Optimizer\tAdam\n",
        "# Shearing\t−0.3 to +.3\n",
        "# Horizontal flipping\tTrue\n",
        "# Rotating\t−10 to +10\n",
        "# Zooming\t0.5 to 1.5\n",
        "# Batch Size\t32\n",
        "# Validation split\t0.2\n",
        "test_datagen = ImageDataGenerator(rescale=1/255.0,# Normalizing images\n",
        "                                shear_range=0.2,\n",
        "                                zoom_range=0.2,\n",
        "                                horizontal_flip=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "j5_9PfTy5zoV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f0950f1-6774-4ee3-ac2b-e72c3aafe6d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 14678 images belonging to 10 classes.\n"
          ]
        }
      ],
      "source": [
        "train_gen = train_datagen.flow_from_directory(\n",
        "                               train_data_dir,\n",
        "                                target_size=(224, 224),\n",
        "                                batch_size=32,\n",
        "                                shuffle=True,\n",
        "                                class_mode='categorical',\n",
        "                                subset='training')\n",
        "# seed=2020 # to make the result reproducible"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "uyx5cL_o54VZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71d6e854-b983-4c66-debb-b0c531e55bd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 915 images belonging to 10 classes.\n"
          ]
        }
      ],
      "source": [
        "val_gen = train_datagen.flow_from_directory(\n",
        "                                val_data_dir,\n",
        "                                target_size=(224,224),\n",
        "                                batch_size=32,\n",
        "                                shuffle=True,\n",
        "                                class_mode='categorical',\n",
        "                                subset='validation')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "35dQ-t9D6CWy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3515d1b-2e0b-43ac-eb5b-5a8bce905311"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 50 images belonging to 10 classes.\n"
          ]
        }
      ],
      "source": [
        "test_gen = test_datagen.flow_from_directory(\n",
        "        test_data_dir,\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical',\n",
        "        shuffle = False) #shuffle will not affect the accuracy of the model, but will affect the computation of some metrics that depend on the order of the samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MmjMGsE76NKy"
      },
      "outputs": [],
      "source": [
        "cnn1 = models.Sequential()\n",
        "\n",
        "cnn1.add(layers.Conv2D (32, kernel_size = (3,3), activation='relu', input_shape = [224, 224,3])),\n",
        "cnn1.add(layers.MaxPooling2D(pool_size = (2, 2))),\n",
        "\n",
        "cnn1.add(layers.Conv2D(64, (3,3), padding ='same', activation='relu')),\n",
        "cnn1.add(layers.Conv2D(64, (3,3), padding ='same', activation='relu')),\n",
        "cnn1.add(layers. MaxPooling2D((2, 2))),\n",
        "\n",
        "cnn1.add(layers.Conv2D(128, (3, 3), padding ='same', activation='relu')),\n",
        "cnn1.add(layers.Conv2D(128, (3,3), padding ='same', activation='relu')),\n",
        "cnn1.add(layers.MaxPooling2D((2, 2))),\n",
        "\n",
        "cnn1.add(layers. Conv2D(256, (3, 3), padding ='same', activation='relu')),\n",
        "cnn1.add(layers.Conv2D(256, (3,3), padding ='same', activation='relu')),\n",
        "cnn1.add(layers.MaxPooling2D((2, 2))),\n",
        "\n",
        "cnn1.add(layers.Conv2D(512, (3, 3), padding ='same', activation='relu')),\n",
        "cnn1.add(layers.Conv2D(512, (3, 3), padding ='same', activation='relu')),\n",
        "cnn1.add(layers.Conv2D(512, (3,3), padding ='same', activation='relu')),\n",
        "cnn1.add(layers.MaxPooling2D((2, 2))),\n",
        "\n",
        "cnn1.add(layers.Conv2D(512, (3, 3), padding ='same', activation='relu')),\n",
        "cnn1.add(layers.Conv2D(512, (3, 3), padding ='same', activation='relu')),\n",
        "cnn1.add(layers.Conv2D(512, (3,3), padding ='same', activation='relu')),\n",
        "cnn1.add(layers.MaxPooling2D((2, 2))),\n",
        "\n",
        "cnn1.add(layers.Flatten()),\n",
        "\n",
        "cnn1.add(layers.Dense(64,activation='relu')),\n",
        "cnn1.add(Dropout(0.24)),\n",
        "#output layer\n",
        "cnn1.add(layers.Dense(10,activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "bZmzSalI6TkY",
        "outputId": "c94bca8d-c01b-4bdd-eb1d-13f9d0076095"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 222, 222, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 111, 111, 32)      0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 111, 111, 64)      18496     \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 111, 111, 64)      36928     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 55, 55, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 55, 55, 128)       73856     \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 55, 55, 128)       147584    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 27, 27, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 27, 27, 256)       295168    \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 27, 27, 256)       590080    \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 13, 13, 256)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 13, 13, 512)       1180160   \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 13, 13, 512)       2359808   \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 13, 13, 512)       2359808   \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPoolin  (None, 6, 6, 512)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 6, 6, 512)         2359808   \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 6, 6, 512)         2359808   \n",
            "                                                                 \n",
            " conv2d_12 (Conv2D)          (None, 6, 6, 512)         2359808   \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPoolin  (None, 3, 3, 512)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 4608)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                294976    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14437834 (55.08 MB)\n",
            "Trainable params: 14437834 (55.08 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "cnn1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "OqD9Nqmd6W8J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "6da3391a-02a6-41f5-a8c1-dd5ba0e37659"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'keras' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-cdd928109990>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'keras' is not defined"
          ]
        }
      ],
      "source": [
        "opt = keras.optimizers.Adam(learning_rate=0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NE2iVK1Y6a7N"
      },
      "outputs": [],
      "source": [
        "cnn1.compile(optimizer=opt,loss='categorical_crossentropy',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "aZ7xx4ew6fFy"
      },
      "outputs": [],
      "source": [
        "# Define early stopping callback\n",
        "es = EarlyStopping(monitor = 'val_accuracy',\n",
        "                   mode = 'max',\n",
        "                   patience = 20,\n",
        "                   verbose = 1,\n",
        "                   restore_best_weights = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Rr-b2fw6ilo",
        "outputId": "d1546276-1deb-41a1-e3d3-ab07a40077c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "139/458 [========>.....................] - ETA: 2:15 - loss: 2.3025 - accuracy: 0.1045"
          ]
        }
      ],
      "source": [
        "history = cnn1.fit(x = train_gen,\n",
        "                    callbacks = [es],\n",
        "                    steps_per_epoch = 14678//32,\n",
        "                    epochs = 20,\n",
        "                    validation_steps = 915//32,\n",
        "                    validation_data = val_gen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_fVAU0-6lwL"
      },
      "outputs": [],
      "source": [
        "scores1 = cnn1.evaluate(test_gen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tiLGh_d7Vs2h"
      },
      "outputs": [],
      "source": [
        "#don't forget to save your model for later\n",
        "cnn1.save('cnn1.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7d5hGy6RH0D"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rOHPq94cjj_"
      },
      "source": [
        "VGG16 Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vl7aqxCWVz5c",
        "outputId": "98d9800b-b4d4-4ccd-fa41-527024427344"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 4s 0us/step\n"
          ]
        }
      ],
      "source": [
        "model1 = VGG16(include_top=False, weights='imagenet',input_shape=(224,224,3))\n",
        "model1.trainable=False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2koIqpKWCWi",
        "outputId": "ad5cae31-4d65-46cf-b620-04a43cd75883"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg16 (Functional)          (None, 7, 7, 512)         14714688  \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                1605696   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16321034 (62.26 MB)\n",
            "Trainable params: 1606346 (6.13 MB)\n",
            "Non-trainable params: 14714688 (56.13 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "cnn2=keras.models.Sequential()\n",
        "cnn2.add(model1)\n",
        "cnn2.add(Flatten())\n",
        "cnn2.add(layers.Dense(64,activation='relu'))\n",
        "cnn2.add(layers.Dense(10,activation='softmax'))\n",
        "cnn2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GCaEUu8Tctlc"
      },
      "outputs": [],
      "source": [
        "opt = keras.optimizers.Adam(learning_rate=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7DwgZJgpWJ3J"
      },
      "outputs": [],
      "source": [
        "cnn2.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "bHgLwLYnbiN4",
        "outputId": "220fa3d5-430b-40c4-ecc2-bb8eab31fd86"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'es' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-1942c65f69e1>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m history = cnn2.fit(x = train_gen,\n\u001b[0;32m----> 2\u001b[0;31m                     \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m                     \u001b[0;31m# steps_per_epoch = 12845//32,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0;31m# validation_steps = 1372//32,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'es' is not defined"
          ]
        }
      ],
      "source": [
        "history = cnn2.fit(x = train_gen,\n",
        "                    callbacks = [es],\n",
        "                    # steps_per_epoch = 12845//32,\n",
        "                    epochs = 20,\n",
        "                    # validation_steps = 1372//32,\n",
        "                    validation_data = val_gen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n7XgjrMbb0hr"
      },
      "outputs": [],
      "source": [
        "scores2 = cnn2.evaluate(test_gen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iy96XvOjcFZ0"
      },
      "outputs": [],
      "source": [
        "cnn2.save('cnn2.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5MRDAOzdbnt"
      },
      "source": [
        "**VGG19** Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfQgnNmHdXei",
        "outputId": "e3f6f448-58e9-4e46-fb64-4efe2db0b20b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80134624/80134624 [==============================] - 5s 0us/step\n"
          ]
        }
      ],
      "source": [
        "model2 = VGG19(include_top=False, weights='imagenet',input_shape=(224,224,3))\n",
        "model2.trainable=False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "id-4wl_XdX-j",
        "outputId": "77a03946-e4cb-4c82-e0af-23a74518d68f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg16 (Functional)          (None, 7, 7, 512)         14714688  \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                1605696   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16321034 (62.26 MB)\n",
            "Trainable params: 1606346 (6.13 MB)\n",
            "Non-trainable params: 14714688 (56.13 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "cnn3=keras.models.Sequential()\n",
        "cnn3.add(model1)\n",
        "cnn3.add(Flatten())\n",
        "cnn3.add(layers.Dense(64,activation='relu'))\n",
        "cnn3.add(layers.Dense(10,activation='softmax'))\n",
        "cnn3.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Vg_f_K0BdYZL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "f8c58fab-b1ba-498e-848e-e323b5b66691"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'keras' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-1af67d4b0c59>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'keras' is not defined"
          ]
        }
      ],
      "source": [
        "opt = keras.optimizers.Adam(learning_rate=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Xs-611_dY3D"
      },
      "outputs": [],
      "source": [
        "cnn3.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rS2v4VwSdZ6O"
      },
      "outputs": [],
      "source": [
        "history = cnn3.fit(x = train_gen,\n",
        "                    callbacks = [es],\n",
        "                    # steps_per_epoch = 12845//32,\n",
        "                    epochs = 20,\n",
        "                    # validation_steps = 1372//32,\n",
        "                    validation_data = val_gen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "QV0FTC0qyeqN",
        "outputId": "82da70b4-340f-47c0-c102-6a5bc1e521f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "101/101 [==============================] - 244s 2s/step - loss: 1.4632 - accuracy: 0.5600 - val_loss: 0.9365 - val_accuracy: 0.7150\n",
            "Epoch 2/20\n",
            "101/101 [==============================] - 195s 2s/step - loss: 0.7107 - accuracy: 0.7791 - val_loss: 0.7362 - val_accuracy: 0.7573\n",
            "Epoch 3/20\n",
            "101/101 [==============================] - 199s 2s/step - loss: 0.5103 - accuracy: 0.8399 - val_loss: 0.6033 - val_accuracy: 0.8207\n",
            "Epoch 4/20\n",
            "101/101 [==============================] - 199s 2s/step - loss: 0.4203 - accuracy: 0.8706 - val_loss: 0.5232 - val_accuracy: 0.8331\n",
            "Epoch 5/20\n",
            "101/101 [==============================] - 200s 2s/step - loss: 0.3445 - accuracy: 0.8965 - val_loss: 0.4809 - val_accuracy: 0.8440\n",
            "Epoch 6/20\n",
            "101/101 [==============================] - 199s 2s/step - loss: 0.2998 - accuracy: 0.9077 - val_loss: 0.5024 - val_accuracy: 0.8331\n",
            "Epoch 7/20\n",
            "101/101 [==============================] - 199s 2s/step - loss: 0.2679 - accuracy: 0.9177 - val_loss: 0.4146 - val_accuracy: 0.8703\n",
            "Epoch 8/20\n",
            "101/101 [==============================] - 198s 2s/step - loss: 0.2334 - accuracy: 0.9306 - val_loss: 0.4294 - val_accuracy: 0.8571\n",
            "Epoch 9/20\n",
            "101/101 [==============================] - 198s 2s/step - loss: 0.2148 - accuracy: 0.9323 - val_loss: 0.3953 - val_accuracy: 0.8797\n",
            "Epoch 10/20\n",
            "101/101 [==============================] - 195s 2s/step - loss: 0.1910 - accuracy: 0.9436 - val_loss: 0.3584 - val_accuracy: 0.8863\n",
            "Epoch 11/20\n",
            "101/101 [==============================] - 196s 2s/step - loss: 0.1813 - accuracy: 0.9457 - val_loss: 0.3963 - val_accuracy: 0.8673\n",
            "Epoch 12/20\n",
            "101/101 [==============================] - 196s 2s/step - loss: 0.1647 - accuracy: 0.9502 - val_loss: 0.3813 - val_accuracy: 0.8608\n",
            "Epoch 13/20\n",
            "101/101 [==============================] - 196s 2s/step - loss: 0.1531 - accuracy: 0.9540 - val_loss: 0.3913 - val_accuracy: 0.8761\n",
            "Epoch 14/20\n",
            "101/101 [==============================] - 199s 2s/step - loss: 0.1390 - accuracy: 0.9619 - val_loss: 0.4200 - val_accuracy: 0.8615\n",
            "Epoch 15/20\n",
            "101/101 [==============================] - 199s 2s/step - loss: 0.1417 - accuracy: 0.9553 - val_loss: 0.4223 - val_accuracy: 0.8601\n",
            "Epoch 16/20\n",
            "101/101 [==============================] - 201s 2s/step - loss: 0.1355 - accuracy: 0.9562 - val_loss: 0.3389 - val_accuracy: 0.8856\n",
            "Epoch 17/20\n",
            "101/101 [==============================] - 197s 2s/step - loss: 0.1152 - accuracy: 0.9653 - val_loss: 0.3264 - val_accuracy: 0.9031\n",
            "Epoch 18/20\n",
            "101/101 [==============================] - 194s 2s/step - loss: 0.1073 - accuracy: 0.9707 - val_loss: 0.3328 - val_accuracy: 0.8856\n",
            "Epoch 19/20\n",
            "101/101 [==============================] - 196s 2s/step - loss: 0.1054 - accuracy: 0.9692 - val_loss: 0.3469 - val_accuracy: 0.8994\n",
            "Epoch 20/20\n",
            "101/101 [==============================] - 195s 2s/step - loss: 0.1111 - accuracy: 0.9639 - val_loss: 0.3786 - val_accuracy: 0.8848\n"
          ]
        }
      ],
      "source": [
        "\n",
        "history_20_epochs = cnn3.fit(x = train_gen,\n",
        "                    callbacks = [es],\n",
        "                    # steps_per_epoch = 12845//32,\n",
        "                    epochs = 20,\n",
        "                    # validation_steps = 1372//32,\n",
        "                    validation_data = val_gen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ct6BzD5xdaYn",
        "outputId": "3330435a-2817-436a-9c9f-54bab9eb5cbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 5s 5s/step - loss: 0.4392 - accuracy: 0.9000\n"
          ]
        }
      ],
      "source": [
        "scores3 = cnn3.evaluate(test_gen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j88nerFufBFJ",
        "outputId": "a83f0e47-f181-4d67-c07e-b4e7292aefeb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "cnn3.save('cnn3.h5')\n",
        "# Complete at 20 epochs on relu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "XYYx5RobnDyk",
        "outputId": "201a0bf0-f77a-4e15-f597-5376580ff71c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg16 (Functional)          (None, 7, 7, 512)         14714688  \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 25088)             0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 64)                1605696   \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16321034 (62.26 MB)\n",
            "Trainable params: 1606346 (6.13 MB)\n",
            "Non-trainable params: 14714688 (56.13 MB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "101/101 [==============================] - 199s 2s/step - loss: 2.5034 - accuracy: 0.3622 - val_loss: 1.8634 - val_accuracy: 0.5109\n",
            "Epoch 2/20\n",
            "101/101 [==============================] - 199s 2s/step - loss: 1.6764 - accuracy: 0.5808 - val_loss: 1.5825 - val_accuracy: 0.6210\n",
            "Epoch 3/20\n",
            "101/101 [==============================] - 207s 2s/step - loss: 1.4683 - accuracy: 0.6547 - val_loss: 1.4186 - val_accuracy: 0.6276\n",
            "Epoch 4/20\n",
            "101/101 [==============================] - 197s 2s/step - loss: 1.2791 - accuracy: 0.7100 - val_loss: 1.2375 - val_accuracy: 0.7085\n",
            "Epoch 5/20\n",
            "101/101 [==============================] - 197s 2s/step - loss: 1.1390 - accuracy: 0.7504 - val_loss: 1.1222 - val_accuracy: 0.7456\n",
            "Epoch 6/20\n",
            "101/101 [==============================] - 200s 2s/step - loss: 1.0121 - accuracy: 0.7910 - val_loss: 1.0289 - val_accuracy: 0.7668\n",
            "Epoch 7/20\n",
            "101/101 [==============================] - 199s 2s/step - loss: 0.8946 - accuracy: 0.8011 - val_loss: 0.9239 - val_accuracy: 0.7668\n",
            "Epoch 8/20\n",
            "101/101 [==============================] - 199s 2s/step - loss: 0.7879 - accuracy: 0.8291 - val_loss: 0.8958 - val_accuracy: 0.7624\n",
            "Epoch 9/20\n",
            "101/101 [==============================] - 200s 2s/step - loss: 0.7233 - accuracy: 0.8367 - val_loss: 0.8074 - val_accuracy: 0.7777\n",
            "Epoch 10/20\n",
            "101/101 [==============================] - 199s 2s/step - loss: 0.6543 - accuracy: 0.8504 - val_loss: 0.7698 - val_accuracy: 0.7850\n",
            "Epoch 11/20\n",
            "101/101 [==============================] - 205s 2s/step - loss: 0.6027 - accuracy: 0.8574 - val_loss: 0.7082 - val_accuracy: 0.7974\n",
            "Epoch 12/20\n",
            " 20/101 [====>.........................] - ETA: 2:22 - loss: 0.5340 - accuracy: 0.8816"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-0243fd3330c8>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m               \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m               metrics=['accuracy'])\n\u001b[0;32m---> 12\u001b[0;31m history_20_epochs_tanh = cnn3.fit(x = train_gen,\n\u001b[0m\u001b[1;32m     13\u001b[0m                     \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0;31m# steps_per_epoch = 12845//32,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1811\u001b[0m                             \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m                             \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1813\u001b[0;31m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1814\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1815\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    473\u001b[0m         \"\"\"\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"end\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    320\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"end\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1093\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m             \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m             \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1170\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    692\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    629\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mwrong\u001b[0m \u001b[0mkeyword\u001b[0m \u001b[0marguments\u001b[0m \u001b[0mare\u001b[0m \u001b[0mprovided\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m   \"\"\"\n\u001b[0;32m--> 631\u001b[0;31m   return nest_util.map_structure(\n\u001b[0m\u001b[1;32m    632\u001b[0m       \u001b[0mnest_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModality\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCORE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest_util.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(modality, func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m   1064\u001b[0m   \"\"\"\n\u001b[1;32m   1065\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmodality\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mModality\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCORE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1066\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_tf_core_map_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1067\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mmodality\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mModality\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_tf_data_map_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest_util.py\u001b[0m in \u001b[0;36m_tf_core_map_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m   1104\u001b[0m   return _tf_core_pack_sequence_as(\n\u001b[1;32m   1105\u001b[0m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m       \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1107\u001b[0m       \u001b[0mexpand_composites\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexpand_composites\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest_util.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1104\u001b[0m   return _tf_core_pack_sequence_as(\n\u001b[1;32m   1105\u001b[0m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m       \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1107\u001b[0m       \u001b[0mexpand_composites\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexpand_composites\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m         \u001b[0;31m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[0;31m# as-is.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    392\u001b[0m     \"\"\"\n\u001b[1;32m    393\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    358\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# created by anurag testing accuracy on tanh at 20 epochs\n",
        "cnn3=keras.models.Sequential()\n",
        "cnn3.add(model1)\n",
        "cnn3.add(Flatten())\n",
        "cnn3.add(layers.Dense(64,activation='tanh'))\n",
        "cnn3.add(layers.Dense(10,activation='softmax'))\n",
        "cnn3.summary()\n",
        "\n",
        "cnn3.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "history_20_epochs_tanh = cnn3.fit(x = train_gen,\n",
        "                    callbacks = [es],\n",
        "                    # steps_per_epoch = 12845//32,\n",
        "                    epochs = 20,\n",
        "                    # validation_steps = 1372//32,\n",
        "                    validation_data = val_gen)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8lFFKIBh5LW"
      },
      "source": [
        "Resnet50 Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "8jS4DS3Xh1R9",
        "outputId": "8ffe0220-348b-44d5-aff5-cdbc4b088c18"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'ResNet50' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-acd3239c6703>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResNet50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ResNet50' is not defined"
          ]
        }
      ],
      "source": [
        "model3 = ResNet50(include_top=False,weights='imagenet',input_shape=(224,224,3),classes=10)\n",
        "model3.trainable=False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q29IjVEHh1t0",
        "outputId": "8deab175-2dda-4920-d2a2-6c4ab358ed00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " tf.cast_1 (TFOpLambda)      (None, 224, 224, 3)       0         \n",
            "                                                                 \n",
            " tf.__operators__.getitem_1  (None, 224, 224, 3)       0         \n",
            "  (SlicingOpLambda)                                              \n",
            "                                                                 \n",
            " tf.nn.bias_add_1 (TFOpLamb  (None, 224, 224, 3)       0         \n",
            " da)                                                             \n",
            "                                                                 \n",
            " resnet50 (Functional)       (None, 7, 7, 2048)        23587712  \n",
            "                                                                 \n",
            " global_average_pooling2d_1  (None, 2048)              0         \n",
            "  (GlobalAveragePooling2D)                                       \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 2048)              8192      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 512)               1049088   \n",
            "                                                                 \n",
            " batch_normalization_3 (Bat  (None, 512)               2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 24652170 (94.04 MB)\n",
            "Trainable params: 1059338 (4.04 MB)\n",
            "Non-trainable params: 23592832 (90.00 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Load pre-trained ResNet50 model without top layers\n",
        "model3 = ResNet50(include_top=False,weights='imagenet',input_shape=(224,224,3),classes=10)\n",
        "\n",
        "# Freeze base model layers\n",
        "for layer in model3.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "pt = Input(shape=(224,224,3))\n",
        "func = tf.cast(pt,tf.float32)\n",
        "x = preprocess_input(func)#This function used to zero-center each color channel wrt Imagenet dataset\n",
        "\n",
        "# Add custom classification layers on top of ResNet50\n",
        "\n",
        "# model_resnet = model3(x,training=False)\n",
        "# model_resnet = GlobalAveragePooling2D()(model_resnet)\n",
        "# model_resnet = Dense(128,activation='relu')(model_resnet)\n",
        "# model_resnet = Dense(64,activation='relu')(model_resnet)\n",
        "# model_resnet = Dense(10,activation='softmax')(model_resnet)\n",
        "\n",
        "model_resnet = model3(x,training=False)\n",
        "model_resnet = GlobalAveragePooling2D()(model_resnet)\n",
        "model_resnet =  BatchNormalization()(model_resnet)\n",
        "model_resnet =  Dropout(0.5)(model_resnet)\n",
        "model_resnet = Dense(512,activation='relu')(model_resnet)\n",
        "model_resnet =  BatchNormalization()(model_resnet)\n",
        "model_resnet =  Dropout(0.5)(model_resnet)\n",
        "model_resnet = Dense(10,activation='softmax')(model_resnet)\n",
        "\n",
        "\n",
        "cnn4 = Model(inputs=pt,outputs=model_resnet)\n",
        "cnn4.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "EmWtLv3dh2IG"
      },
      "outputs": [],
      "source": [
        "cnn4.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "zsAmgmrJh2iF"
      },
      "outputs": [],
      "source": [
        "# Define learning rate reduction callback\n",
        "lr=ReduceLROnPlateau(monitor='val_accuracy',verbose=1,patience=5,min_lr=0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvDOPCQih273",
        "outputId": "c2af1310-0382-4312-82e0-fd2e51383599"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "459/459 [==============================] - 3347s 7s/step - loss: 2.1022 - accuracy: 0.3600 - val_loss: 1.7890 - val_accuracy: 0.3694 - lr: 0.0010\n",
            "Epoch 2/20\n",
            "459/459 [==============================] - 3446s 8s/step - loss: 1.6394 - accuracy: 0.4458 - val_loss: 1.2889 - val_accuracy: 0.5519 - lr: 0.0010\n",
            "Epoch 3/20\n",
            "459/459 [==============================] - 3338s 7s/step - loss: 1.5302 - accuracy: 0.4743 - val_loss: 1.2095 - val_accuracy: 0.5661 - lr: 0.0010\n",
            "Epoch 4/20\n",
            "459/459 [==============================] - 3356s 7s/step - loss: 1.4426 - accuracy: 0.4999 - val_loss: 1.1885 - val_accuracy: 0.5847 - lr: 0.0010\n",
            "Epoch 5/20\n",
            "459/459 [==============================] - 3328s 7s/step - loss: 1.4093 - accuracy: 0.5076 - val_loss: 1.1856 - val_accuracy: 0.5770 - lr: 0.0010\n",
            "Epoch 6/20\n",
            "459/459 [==============================] - 3289s 7s/step - loss: 1.4045 - accuracy: 0.5089 - val_loss: 1.1661 - val_accuracy: 0.6000 - lr: 0.0010\n",
            "Epoch 7/20\n",
            "362/459 [======================>.......] - ETA: 10:58 - loss: 1.3528 - accuracy: 0.5256"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "cnn4_history_at_20_epochs_resnet = cnn4.fit(x = train_gen,\n",
        "                    callbacks = [es,lr],\n",
        "                    # steps_per_epoch = 12845//32,\n",
        "                    epochs = 20,\n",
        "                    # validation_steps = 1372//32,\n",
        "                    validation_data = val_gen)\n",
        "\n",
        "history = model3.fit(train_gen, epochs=20, validation_data=val_gen, callbacks=[es, lr])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QlViHnqth3YI"
      },
      "outputs": [],
      "source": [
        "scores4 = cnn4.evaluate(test_gen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9fvhvm8xvHlF",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "cnn4.save('cnn4.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5J6eAzdRty8"
      },
      "source": [
        "### Resnet50 Model change parmeter to gain accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "r7KYSgos5dPF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " resnet50 by anurag gupta\n"
      ],
      "metadata": {
        "id": "EM51QJHU6IFj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# resnet50 by anurag gupta\n",
        "\n",
        "# es = EarlyStopping(monitor = 'val_accuracy',\n",
        "#                    mode = 'max',\n",
        "#                    patience = 20,\n",
        "#                    verbose = 1,\n",
        "#                    restore_best_weights = True)\n",
        "\n",
        "# # Load pre-trained ResNet50 model without top layers\n",
        "# model3 = ResNet50(include_top=False,weights='imagenet',input_shape=(224,224,3),classes=10)\n",
        "\n",
        "# # Freeze base model layers\n",
        "# for layer in model3.layers:\n",
        "#     layer.trainable = False\n",
        "# pt = Input(shape=(224,224,3))\n",
        "# func = tf.cast(pt,tf.float32)\n",
        "# x = preprocess_input(func)\n",
        "\n",
        "# #This function used to zero-center each color channel wrt Imagenet dataset\n",
        "# opt = keras.optimizers.Adam(learning_rate=0.1)\n",
        "\n",
        "# model_resnet = model3(x,training=False)\n",
        "# model_resnet = GlobalAveragePooling2D()(model_resnet)\n",
        "# model_resnet = Dense(128,activation='relu')(model_resnet)\n",
        "# model_resnet = Dense(64,activation='relu')(model_resnet)\n",
        "# model_resnet = Dense(10,activation='softmax')(model_resnet)\n",
        "\n",
        "\n",
        "# cnn4 = Model(inputs=pt,outputs=model_resnet)\n",
        "# cnn4.summary()\n",
        "\n",
        "# cnn4.compile(optimizer='adam',\n",
        "#               loss='categorical_crossentropy',\n",
        "#              metrics=['accuracy'])\n",
        "# # Define learning rate reduction callback"
      ],
      "metadata": {
        "id": "5IZ6OEeu5Awv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "lr=ReduceLROnPlateau(monitor='val_accuracy',verbose=1,patience=5,min_lr=0.0001)\n",
        "\n",
        "\n",
        "es = EarlyStopping(monitor = 'val_accuracy',\n",
        "                   mode = 'max',\n",
        "                   patience = 20,\n",
        "                   verbose = 1,\n",
        "                   restore_best_weights = True)\n",
        "\n",
        "\n",
        "\n",
        "# Load pre-trained ResNet50 model without top layers\n",
        "base_model = ResNet50(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze base model layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add custom classification layers on top of ResNet50\n",
        "x = GlobalAveragePooling2D()(base_model.output)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "output = Dense(10, activation='softmax')(x)\n",
        "\n",
        "# Define the model\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define data generators\n",
        "train_data_dir = '/content/tomato_dataset/train'\n",
        "test_data_dir = '/content/tomato_dataset/test'\n",
        "val_data_dir = '/content/tomato_dataset/valid'\n",
        "\n",
        "train_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.resnet.preprocess_input)\n",
        "val_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.resnet.preprocess_input)\n",
        "\n",
        "train_gen = train_datagen.flow_from_directory(train_data_dir, target_size=(224, 224), batch_size=32, class_mode='categorical')\n",
        "val_gen = val_datagen.flow_from_directory(val_data_dir, target_size=(224, 224), batch_size=32, class_mode='categorical')\n",
        "\n"
      ],
      "metadata": {
        "id": "HbjEUDqs639N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd097ae6-ed69-4dbf-b69b-22c0a38502e7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 18345 images belonging to 10 classes.\n",
            "Found 4585 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Train the model\n",
        "history = model.fit(train_gen, epochs=20, validation_data=val_gen, callbacks=[es, lr])\n"
      ],
      "metadata": {
        "id": "nQFHGhh79Dry",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "c8f1050b-656d-4b6d-ac35-c98ba91db74b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            " 33/574 [>.............................] - ETA: 58s - loss: 0.0139 - accuracy: 0.9953"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-253992ba02d1>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## resnet50 with dropout layers\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Load pre-trained ResNet50 model without top layers\n",
        "base_model = ResNet50(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze base model layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "\n",
        "# model_resnet = model3(x,training=False)\n",
        "model_resnet = GlobalAveragePooling2D()(base_model.output)\n",
        "model_resnet =  BatchNormalization()(model_resnet)\n",
        "model_resnet =  Dropout(0.5)(model_resnet)\n",
        "model_resnet = Dense(512,activation='relu')(model_resnet)\n",
        "model_resnet =  BatchNormalization()(model_resnet)\n",
        "model_resnet =  Dropout(0.5)(model_resnet)\n",
        "output = Dense(10,activation='softmax')(model_resnet)\n",
        "\n",
        "# Add custom classification layers on top of ResNet50\n",
        "# x = GlobalAveragePooling2D()(base_model.output)\n",
        "# x = Dense(128, activation='relu')(x)\n",
        "# x = Dense(64, activation='relu')(x)\n",
        "# output = Dense(10, activation='softmax')(x)\n",
        "\n",
        "# Define the model\n",
        "model_with_dropout = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# Compile the model\n",
        "model_with_dropout.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define data generators\n",
        "train_data_dir = '/content/tomato_dataset/train'\n",
        "test_data_dir = '/content/tomato_dataset/test'\n",
        "val_data_dir = '/content/tomato_dataset/valid'\n",
        "train_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.resnet.preprocess_input)\n",
        "val_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.resnet.preprocess_input)\n",
        "\n",
        "train_gen = train_datagen.flow_from_directory(train_data_dir, target_size=(224, 224), batch_size=32, class_mode='categorical')\n",
        "val_gen = val_datagen.flow_from_directory(val_data_dir, target_size=(224, 224), batch_size=32, class_mode='categorical')\n",
        "\n",
        "# Train the model\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7JKbCmv8Nir",
        "outputId": "a8241d78-34d5-4e99-8ca2-2ff747838685"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 18345 images belonging to 10 classes.\n",
            "Found 4585 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_with_dropout.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPoNtTH_9LL7",
        "outputId": "294b4841-8e60-4d20-aa3e-f8fbb687774e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_6 (InputLayer)        [(None, 224, 224, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " conv1_pad (ZeroPadding2D)   (None, 230, 230, 3)          0         ['input_6[0][0]']             \n",
            "                                                                                                  \n",
            " conv1_conv (Conv2D)         (None, 112, 112, 64)         9472      ['conv1_pad[0][0]']           \n",
            "                                                                                                  \n",
            " conv1_bn (BatchNormalizati  (None, 112, 112, 64)         256       ['conv1_conv[0][0]']          \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv1_relu (Activation)     (None, 112, 112, 64)         0         ['conv1_bn[0][0]']            \n",
            "                                                                                                  \n",
            " pool1_pad (ZeroPadding2D)   (None, 114, 114, 64)         0         ['conv1_relu[0][0]']          \n",
            "                                                                                                  \n",
            " pool1_pool (MaxPooling2D)   (None, 56, 56, 64)           0         ['pool1_pad[0][0]']           \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2  (None, 56, 56, 64)           4160      ['pool1_pool[0][0]']          \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNo  (None, 56, 56, 64)           256       ['conv2_block1_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activ  (None, 56, 56, 64)           0         ['conv2_block1_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2  (None, 56, 56, 64)           36928     ['conv2_block1_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_bn (BatchNo  (None, 56, 56, 64)           256       ['conv2_block1_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block1_2_relu (Activ  (None, 56, 56, 64)           0         ['conv2_block1_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block1_0_conv (Conv2  (None, 56, 56, 256)          16640     ['pool1_pool[0][0]']          \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_3_conv (Conv2  (None, 56, 56, 256)          16640     ['conv2_block1_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_0_bn (BatchNo  (None, 56, 56, 256)          1024      ['conv2_block1_0_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block1_3_bn (BatchNo  (None, 56, 56, 256)          1024      ['conv2_block1_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block1_add (Add)      (None, 56, 56, 256)          0         ['conv2_block1_0_bn[0][0]',   \n",
            "                                                                     'conv2_block1_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv2_block1_out (Activati  (None, 56, 56, 256)          0         ['conv2_block1_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2  (None, 56, 56, 64)           16448     ['conv2_block1_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNo  (None, 56, 56, 64)           256       ['conv2_block2_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activ  (None, 56, 56, 64)           0         ['conv2_block2_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2  (None, 56, 56, 64)           36928     ['conv2_block2_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_bn (BatchNo  (None, 56, 56, 64)           256       ['conv2_block2_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block2_2_relu (Activ  (None, 56, 56, 64)           0         ['conv2_block2_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block2_3_conv (Conv2  (None, 56, 56, 256)          16640     ['conv2_block2_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_3_bn (BatchNo  (None, 56, 56, 256)          1024      ['conv2_block2_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block2_add (Add)      (None, 56, 56, 256)          0         ['conv2_block1_out[0][0]',    \n",
            "                                                                     'conv2_block2_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv2_block2_out (Activati  (None, 56, 56, 256)          0         ['conv2_block2_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2  (None, 56, 56, 64)           16448     ['conv2_block2_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNo  (None, 56, 56, 64)           256       ['conv2_block3_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activ  (None, 56, 56, 64)           0         ['conv2_block3_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2  (None, 56, 56, 64)           36928     ['conv2_block3_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_bn (BatchNo  (None, 56, 56, 64)           256       ['conv2_block3_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block3_2_relu (Activ  (None, 56, 56, 64)           0         ['conv2_block3_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block3_3_conv (Conv2  (None, 56, 56, 256)          16640     ['conv2_block3_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_3_bn (BatchNo  (None, 56, 56, 256)          1024      ['conv2_block3_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block3_add (Add)      (None, 56, 56, 256)          0         ['conv2_block2_out[0][0]',    \n",
            "                                                                     'conv2_block3_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv2_block3_out (Activati  (None, 56, 56, 256)          0         ['conv2_block3_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2  (None, 28, 28, 128)          32896     ['conv2_block3_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block1_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block1_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2  (None, 28, 28, 128)          147584    ['conv3_block1_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_2_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block1_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block1_2_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block1_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block1_0_conv (Conv2  (None, 28, 28, 512)          131584    ['conv2_block3_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_3_conv (Conv2  (None, 28, 28, 512)          66048     ['conv3_block1_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_0_bn (BatchNo  (None, 28, 28, 512)          2048      ['conv3_block1_0_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block1_3_bn (BatchNo  (None, 28, 28, 512)          2048      ['conv3_block1_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block1_add (Add)      (None, 28, 28, 512)          0         ['conv3_block1_0_bn[0][0]',   \n",
            "                                                                     'conv3_block1_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block1_out (Activati  (None, 28, 28, 512)          0         ['conv3_block1_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2  (None, 28, 28, 128)          65664     ['conv3_block1_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block2_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block2_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2  (None, 28, 28, 128)          147584    ['conv3_block2_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_2_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block2_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block2_2_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block2_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block2_3_conv (Conv2  (None, 28, 28, 512)          66048     ['conv3_block2_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_3_bn (BatchNo  (None, 28, 28, 512)          2048      ['conv3_block2_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block2_add (Add)      (None, 28, 28, 512)          0         ['conv3_block1_out[0][0]',    \n",
            "                                                                     'conv3_block2_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block2_out (Activati  (None, 28, 28, 512)          0         ['conv3_block2_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2  (None, 28, 28, 128)          65664     ['conv3_block2_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block3_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block3_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2  (None, 28, 28, 128)          147584    ['conv3_block3_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_2_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block3_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block3_2_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block3_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block3_3_conv (Conv2  (None, 28, 28, 512)          66048     ['conv3_block3_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_3_bn (BatchNo  (None, 28, 28, 512)          2048      ['conv3_block3_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block3_add (Add)      (None, 28, 28, 512)          0         ['conv3_block2_out[0][0]',    \n",
            "                                                                     'conv3_block3_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block3_out (Activati  (None, 28, 28, 512)          0         ['conv3_block3_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2  (None, 28, 28, 128)          65664     ['conv3_block3_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block4_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block4_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2  (None, 28, 28, 128)          147584    ['conv3_block4_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_2_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block4_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block4_2_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block4_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block4_3_conv (Conv2  (None, 28, 28, 512)          66048     ['conv3_block4_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_3_bn (BatchNo  (None, 28, 28, 512)          2048      ['conv3_block4_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block4_add (Add)      (None, 28, 28, 512)          0         ['conv3_block3_out[0][0]',    \n",
            "                                                                     'conv3_block4_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block4_out (Activati  (None, 28, 28, 512)          0         ['conv3_block4_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2  (None, 14, 14, 256)          131328    ['conv3_block4_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block1_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block1_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2  (None, 14, 14, 256)          590080    ['conv4_block1_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_2_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block1_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block1_2_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block1_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block1_0_conv (Conv2  (None, 14, 14, 1024)         525312    ['conv3_block4_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_3_conv (Conv2  (None, 14, 14, 1024)         263168    ['conv4_block1_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_0_bn (BatchNo  (None, 14, 14, 1024)         4096      ['conv4_block1_0_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block1_3_bn (BatchNo  (None, 14, 14, 1024)         4096      ['conv4_block1_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block1_add (Add)      (None, 14, 14, 1024)         0         ['conv4_block1_0_bn[0][0]',   \n",
            "                                                                     'conv4_block1_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block1_out (Activati  (None, 14, 14, 1024)         0         ['conv4_block1_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2  (None, 14, 14, 256)          262400    ['conv4_block1_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block2_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block2_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2  (None, 14, 14, 256)          590080    ['conv4_block2_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_2_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block2_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block2_2_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block2_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block2_3_conv (Conv2  (None, 14, 14, 1024)         263168    ['conv4_block2_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_3_bn (BatchNo  (None, 14, 14, 1024)         4096      ['conv4_block2_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block2_add (Add)      (None, 14, 14, 1024)         0         ['conv4_block1_out[0][0]',    \n",
            "                                                                     'conv4_block2_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block2_out (Activati  (None, 14, 14, 1024)         0         ['conv4_block2_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2  (None, 14, 14, 256)          262400    ['conv4_block2_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block3_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block3_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2  (None, 14, 14, 256)          590080    ['conv4_block3_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_2_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block3_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block3_2_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block3_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block3_3_conv (Conv2  (None, 14, 14, 1024)         263168    ['conv4_block3_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_3_bn (BatchNo  (None, 14, 14, 1024)         4096      ['conv4_block3_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block3_add (Add)      (None, 14, 14, 1024)         0         ['conv4_block2_out[0][0]',    \n",
            "                                                                     'conv4_block3_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block3_out (Activati  (None, 14, 14, 1024)         0         ['conv4_block3_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2  (None, 14, 14, 256)          262400    ['conv4_block3_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block4_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block4_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2  (None, 14, 14, 256)          590080    ['conv4_block4_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_2_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block4_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block4_2_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block4_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block4_3_conv (Conv2  (None, 14, 14, 1024)         263168    ['conv4_block4_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_3_bn (BatchNo  (None, 14, 14, 1024)         4096      ['conv4_block4_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block4_add (Add)      (None, 14, 14, 1024)         0         ['conv4_block3_out[0][0]',    \n",
            "                                                                     'conv4_block4_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block4_out (Activati  (None, 14, 14, 1024)         0         ['conv4_block4_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2  (None, 14, 14, 256)          262400    ['conv4_block4_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block5_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block5_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2  (None, 14, 14, 256)          590080    ['conv4_block5_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_2_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block5_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block5_2_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block5_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block5_3_conv (Conv2  (None, 14, 14, 1024)         263168    ['conv4_block5_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_3_bn (BatchNo  (None, 14, 14, 1024)         4096      ['conv4_block5_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block5_add (Add)      (None, 14, 14, 1024)         0         ['conv4_block4_out[0][0]',    \n",
            "                                                                     'conv4_block5_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block5_out (Activati  (None, 14, 14, 1024)         0         ['conv4_block5_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2  (None, 14, 14, 256)          262400    ['conv4_block5_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block6_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block6_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2  (None, 14, 14, 256)          590080    ['conv4_block6_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_2_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block6_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block6_2_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block6_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block6_3_conv (Conv2  (None, 14, 14, 1024)         263168    ['conv4_block6_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_3_bn (BatchNo  (None, 14, 14, 1024)         4096      ['conv4_block6_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block6_add (Add)      (None, 14, 14, 1024)         0         ['conv4_block5_out[0][0]',    \n",
            "                                                                     'conv4_block6_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block6_out (Activati  (None, 14, 14, 1024)         0         ['conv4_block6_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block1_1_conv (Conv2  (None, 7, 7, 512)            524800    ['conv4_block6_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_1_bn (BatchNo  (None, 7, 7, 512)            2048      ['conv5_block1_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block1_1_relu (Activ  (None, 7, 7, 512)            0         ['conv5_block1_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block1_2_conv (Conv2  (None, 7, 7, 512)            2359808   ['conv5_block1_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_2_bn (BatchNo  (None, 7, 7, 512)            2048      ['conv5_block1_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block1_2_relu (Activ  (None, 7, 7, 512)            0         ['conv5_block1_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block1_0_conv (Conv2  (None, 7, 7, 2048)           2099200   ['conv4_block6_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_3_conv (Conv2  (None, 7, 7, 2048)           1050624   ['conv5_block1_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_0_bn (BatchNo  (None, 7, 7, 2048)           8192      ['conv5_block1_0_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block1_3_bn (BatchNo  (None, 7, 7, 2048)           8192      ['conv5_block1_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block1_add (Add)      (None, 7, 7, 2048)           0         ['conv5_block1_0_bn[0][0]',   \n",
            "                                                                     'conv5_block1_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block1_out (Activati  (None, 7, 7, 2048)           0         ['conv5_block1_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block2_1_conv (Conv2  (None, 7, 7, 512)            1049088   ['conv5_block1_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_1_bn (BatchNo  (None, 7, 7, 512)            2048      ['conv5_block2_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block2_1_relu (Activ  (None, 7, 7, 512)            0         ['conv5_block2_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block2_2_conv (Conv2  (None, 7, 7, 512)            2359808   ['conv5_block2_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_2_bn (BatchNo  (None, 7, 7, 512)            2048      ['conv5_block2_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block2_2_relu (Activ  (None, 7, 7, 512)            0         ['conv5_block2_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block2_3_conv (Conv2  (None, 7, 7, 2048)           1050624   ['conv5_block2_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_3_bn (BatchNo  (None, 7, 7, 2048)           8192      ['conv5_block2_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block2_add (Add)      (None, 7, 7, 2048)           0         ['conv5_block1_out[0][0]',    \n",
            "                                                                     'conv5_block2_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block2_out (Activati  (None, 7, 7, 2048)           0         ['conv5_block2_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block3_1_conv (Conv2  (None, 7, 7, 512)            1049088   ['conv5_block2_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_1_bn (BatchNo  (None, 7, 7, 512)            2048      ['conv5_block3_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block3_1_relu (Activ  (None, 7, 7, 512)            0         ['conv5_block3_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block3_2_conv (Conv2  (None, 7, 7, 512)            2359808   ['conv5_block3_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_2_bn (BatchNo  (None, 7, 7, 512)            2048      ['conv5_block3_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block3_2_relu (Activ  (None, 7, 7, 512)            0         ['conv5_block3_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block3_3_conv (Conv2  (None, 7, 7, 2048)           1050624   ['conv5_block3_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_3_bn (BatchNo  (None, 7, 7, 2048)           8192      ['conv5_block3_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block3_add (Add)      (None, 7, 7, 2048)           0         ['conv5_block2_out[0][0]',    \n",
            "                                                                     'conv5_block3_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block3_out (Activati  (None, 7, 7, 2048)           0         ['conv5_block3_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " global_average_pooling2d_5  (None, 2048)                 0         ['conv5_block3_out[0][0]']    \n",
            "  (GlobalAveragePooling2D)                                                                        \n",
            "                                                                                                  \n",
            " batch_normalization (Batch  (None, 2048)                 8192      ['global_average_pooling2d_5[0\n",
            " Normalization)                                                     ][0]']                        \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 2048)                 0         ['batch_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " dense_12 (Dense)            (None, 512)                  1049088   ['dropout[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (Bat  (None, 512)                  2048      ['dense_12[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)         (None, 512)                  0         ['batch_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dense_13 (Dense)            (None, 10)                   5130      ['dropout_1[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 24652170 (94.04 MB)\n",
            "Trainable params: 1059338 (4.04 MB)\n",
            "Non-trainable params: 23592832 (90.00 MB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_with_dropout = model_with_dropout.fit(train_gen, epochs=20, validation_data=val_gen, callbacks=[es, lr])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYlkgoUd9IKb",
        "outputId": "ed016112-1d11-4f43-9142-037382eb169f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "574/574 [==============================] - 85s 138ms/step - loss: 0.5458 - accuracy: 0.8286 - val_loss: 0.1501 - val_accuracy: 0.9466 - lr: 0.0010\n",
            "Epoch 2/20\n",
            "574/574 [==============================] - 79s 137ms/step - loss: 0.2699 - accuracy: 0.9084 - val_loss: 0.1121 - val_accuracy: 0.9597 - lr: 0.0010\n",
            "Epoch 3/20\n",
            "574/574 [==============================] - 78s 136ms/step - loss: 0.2215 - accuracy: 0.9244 - val_loss: 0.1063 - val_accuracy: 0.9638 - lr: 0.0010\n",
            "Epoch 4/20\n",
            "574/574 [==============================] - 78s 137ms/step - loss: 0.1979 - accuracy: 0.9340 - val_loss: 0.0928 - val_accuracy: 0.9682 - lr: 0.0010\n",
            "Epoch 5/20\n",
            "574/574 [==============================] - 84s 146ms/step - loss: 0.1748 - accuracy: 0.9389 - val_loss: 0.0856 - val_accuracy: 0.9706 - lr: 0.0010\n",
            "Epoch 6/20\n",
            "574/574 [==============================] - 79s 138ms/step - loss: 0.1675 - accuracy: 0.9412 - val_loss: 0.0788 - val_accuracy: 0.9762 - lr: 0.0010\n",
            "Epoch 7/20\n",
            "574/574 [==============================] - 78s 136ms/step - loss: 0.1592 - accuracy: 0.9421 - val_loss: 0.0767 - val_accuracy: 0.9751 - lr: 0.0010\n",
            "Epoch 8/20\n",
            "574/574 [==============================] - 79s 137ms/step - loss: 0.1532 - accuracy: 0.9469 - val_loss: 0.0706 - val_accuracy: 0.9738 - lr: 0.0010\n",
            "Epoch 9/20\n",
            "574/574 [==============================] - 79s 138ms/step - loss: 0.1504 - accuracy: 0.9469 - val_loss: 0.0661 - val_accuracy: 0.9797 - lr: 0.0010\n",
            "Epoch 10/20\n",
            "574/574 [==============================] - 84s 146ms/step - loss: 0.1410 - accuracy: 0.9513 - val_loss: 0.0673 - val_accuracy: 0.9791 - lr: 0.0010\n",
            "Epoch 11/20\n",
            "574/574 [==============================] - 79s 137ms/step - loss: 0.1329 - accuracy: 0.9541 - val_loss: 0.0638 - val_accuracy: 0.9806 - lr: 0.0010\n",
            "Epoch 12/20\n",
            "574/574 [==============================] - 79s 138ms/step - loss: 0.1266 - accuracy: 0.9572 - val_loss: 0.0650 - val_accuracy: 0.9795 - lr: 0.0010\n",
            "Epoch 13/20\n",
            "574/574 [==============================] - 78s 136ms/step - loss: 0.1220 - accuracy: 0.9591 - val_loss: 0.0583 - val_accuracy: 0.9810 - lr: 0.0010\n",
            "Epoch 14/20\n",
            "574/574 [==============================] - 84s 146ms/step - loss: 0.1195 - accuracy: 0.9575 - val_loss: 0.0611 - val_accuracy: 0.9795 - lr: 0.0010\n",
            "Epoch 15/20\n",
            "574/574 [==============================] - 78s 136ms/step - loss: 0.1189 - accuracy: 0.9582 - val_loss: 0.0597 - val_accuracy: 0.9819 - lr: 0.0010\n",
            "Epoch 16/20\n",
            "574/574 [==============================] - 78s 137ms/step - loss: 0.1106 - accuracy: 0.9632 - val_loss: 0.0549 - val_accuracy: 0.9806 - lr: 0.0010\n",
            "Epoch 17/20\n",
            "574/574 [==============================] - 78s 136ms/step - loss: 0.1037 - accuracy: 0.9628 - val_loss: 0.0642 - val_accuracy: 0.9773 - lr: 0.0010\n",
            "Epoch 18/20\n",
            "574/574 [==============================] - 79s 138ms/step - loss: 0.0952 - accuracy: 0.9658 - val_loss: 0.0570 - val_accuracy: 0.9826 - lr: 0.0010\n",
            "Epoch 19/20\n",
            "574/574 [==============================] - 79s 138ms/step - loss: 0.1002 - accuracy: 0.9642 - val_loss: 0.0608 - val_accuracy: 0.9802 - lr: 0.0010\n",
            "Epoch 20/20\n",
            "574/574 [==============================] - 80s 139ms/step - loss: 0.0968 - accuracy: 0.9663 - val_loss: 0.0582 - val_accuracy: 0.9788 - lr: 0.0010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "load_model = tf.keras.models.load_model(\"/content/cnnResnet50_with_dropout.h5\")"
      ],
      "metadata": {
        "id": "uqMk6ksd9iSy"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FTl9ZBSUF8lT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQimwLXdF-Qr",
        "outputId": "c656d1a8-5853-454d-fdfc-9d8af38b4e27"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_with_dropout.save('./drive/MyDrive/cnnModel/cnnResnet50_with_dropout.h5')"
      ],
      "metadata": {
        "id": "DV9hQw8HFNtj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.flush_and_unmount()"
      ],
      "metadata": {
        "id": "EmNkBEUoIUoQ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores4_with_dropout = model_with_dropout.evaluate(train_gen)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoUtSsH6CSsy",
        "outputId": "9b7e2a6a-9f7b-4a2a-b5d8-165e342407d8"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "574/574 [==============================] - 63s 109ms/step - loss: 0.0054 - accuracy: 0.9995\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot training and validation loss\n",
        "plt.plot(history_with_dropout.history['loss'], label='Training Loss')\n",
        "plt.plot(history_with_dropout.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot training and validation accuracy\n",
        "plt.plot(history_with_dropout.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history_with_dropout.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(test_data_dir)\n",
        "print(f'Test Loss: {test_loss}, Test Accuracy: {test_accuracy}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IJ8fvEuMIwW4",
        "outputId": "5c46f7c6-2d34-4146-9a5e-c5f5d3d49727"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "tuple index out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-196cd61c2456>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Evaluate the model on the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Test Loss: {test_loss}, Test Accuracy: {test_accuracy}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    960\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_v2_behavior\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 962\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    963\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fw24XTnSJIB"
      },
      "source": [
        "### Task VGG16/19:: Run model at 20 epoch and save it\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BNnMh1uD665p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "66372557-284b-44a2-b99e-c96dae8bcf83"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'history' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-891fe62a7ddb>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Training loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Validation loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ],
      "source": [
        "# plt.plot(history.history['loss'], label='Training loss')\n",
        "# plt.plot(history.history['val_loss'], label='Validation loss')\n",
        "# plt.legend()\n",
        "# plt.show()\n",
        "\n",
        "# # plot the accuracy\n",
        "# plt.plot(history.history['accuracy'], label='Training accuracy')\n",
        "# plt.plot(history.history['val_accuracy'], label='Validation accuracy')\n",
        "# plt.legend()\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPB51MBA667a"
      },
      "outputs": [],
      "source": [
        "# test_steps_per_epoch = np.math.ceil(test_gen.samples / test_gen.batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D32HJmS666-w"
      },
      "outputs": [],
      "source": [
        "# # Predict classes\n",
        "# predictions = cnn.predict(test_gen, steps=test_steps_per_epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AiPfhyjG7FpB"
      },
      "outputs": [],
      "source": [
        "# predictions[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-FLpeHE7FrV"
      },
      "outputs": [],
      "source": [
        "# predicted_classes = np.argmax(predictions,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "srY1zTAA7FtY"
      },
      "outputs": [],
      "source": [
        "# # Get ground-truth classes and class-labels\n",
        "# true_classes = test_gen.classes\n",
        "# class_labels = list(test_gen.class_indices.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WMF1I_wp7Fw7"
      },
      "outputs": [],
      "source": [
        "# # Print confusion matrix\n",
        "# confusion_matrix = confusion_matrix(test_gen.classes, predicted_classes)\n",
        "# print(confusion_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mrhv8pTt7O6s"
      },
      "outputs": [],
      "source": [
        "# report = classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
        "# print(report)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}